# Synthetic.new — Secondary Provider for Model Flexibility

Synthetic.new is a privacy-first AI model provider offering access to frontier open-source models with competitive pricing and impressive performance.

## My Role for Synthetic.new

In my dual-provider workflow, **Synthetic.new is my secondary provider** that I switch to when I need model flexibility:

- **MiniMax**: When I want variety or faster responses
- **Kimi thinking**: When I'm stuck on complex problems requiring deep reasoning
- **Default (GLM-4.6)**: I use [GLM Coding Plan](./glm-coding-plan.md) for everyday work

**When to switch to Synthetic:**
- GLM isn't giving the results you need after 2-3 attempts
- You want a different model's perspective on a problem
- You're working on complex architecture decisions (Kimi thinking)
- You need faster responses for quick iterations (MiniMax)

[Sign up with my referral for $10 first month](https://synthetic.new/?referral=IDyp75aoQpW9YFt)

## Pricing Plans

### Standard Plan - $20/month
- Perfect for individuals starting out
- Access to all always-on models
- Both UI and API access
- Cancel anytime
- Standard rate limits: 135 messages every five hours
- **3x higher rate limits than Claude's $20/month plan**

### Pro Plan - $60/month
- For professionals and avid LLM users
- Access to all always-on models
- Both UI and API access
- Cancel anytime
- **10x higher rate limits: 1,350 messages every five hours**
- 6x higher rate limits than Claude's $100/month plan
- 50% higher rate limits than Claude's $200/month plan

### Usage-Based Plan
- For enterprise users and custom models
- Pay-per-token for always-on models
- Pay-per-minute for on-demand models
- UI and API access included

## Key Features

- **All-inclusive pricing**: One flat monthly price includes all always-on models
- **No weekly limits**: Only rate limits per 5-hour window
- **Extensive model library**: 20+ frontier models including DeepSeek, Llama, Qwen, GLM, and MiniMax
- **Privacy-first approach**: No worries about code privacy
- **High-speed performance**: Up to 200 tokens per second
- **Regular updates**: New models added frequently

## Hands-On Testing Experience

The author of this guide is currently testing a Synthetic.new subscription using the octofriend CLI, and the offering has proven impressive on several fronts:

### Performance & Speed
The API works seamlessly with very good performance. GLM-4.6 reaches **200 tokens per second**, making it twice as fast as the GLM coding plan from z.ai. This speed advantage is consistent across the model lineup.

### Privacy Advantage
What makes Synthetic.new stand out is its **privacy-first approach**. There's no need to worry about the privacy of code you're developing, which is crucial for professional development work.

### Value Proposition
For a fair price, you receive **3x the amount of messages** compared to Claude Code, plus access to the majority of frontier open-source models. The seamless experience across all areas makes it compelling for:

1. **Privacy-conscious developers** who want to ensure their code remains private
2. **Model experimenters** who want to test different model schemes without multiple providers
3. **Developers seeking reliability** with single-provider uptime and consistent speed

### Competitive Edge
Compared to alternatives like OpenRouter or Chutes.ai:
- **Speed advantage**: Synthetic.new delivers significantly faster response times
- **Reliability**: Better uptime and more consistent performance
- **Simplicity**: Single provider access to multiple models vs managing multiple services

### Model Innovation
Synthetic.new frequently introduces new models like MiniMax M2, providing easy access to cutting-edge models alongside established ones like DeepSeek. This rapid model rollout keeps developers at the forefront of AI capabilities.

The combination of privacy, performance, competitive pricing, and extensive model selection makes Synthetic.new an intriguing option for developers looking for a comprehensive AI model solution.

---

## Workflow Integration

**Best Used In:**
- [Phase 1: Planning](../workflow/phase-1-planning.md) - Privacy-first planning discussions
- [Phase 2: Development](../workflow/phase-2-development.md) - Code generation with privacy assurance
- [Phase 3: Testing & Debugging](../workflow/phase-3-testing-debugging.md) - Secure debugging sessions

**Privacy-First Workflows:**
- [Droid CLI](../development-tools/recommended-tools/droid-cli.md) — Private coding assistance
- [Context7 MCP](../development-tools/mcp-servers/context7-mcp.md) — Secure documentation access
- [Octofriend CLI](../development-tools/honorable-mentions/octofriend.md) — Tested integration

**Budget Comparison:**
- Compare with [GLM Coding Plan](glm-coding-plan.md) for cost analysis
- Consider [free alternatives](./honorable-mentions/README.md) for budget constraints
- See [Phase 0 tool selection](../workflow/phase-0-vibecoder-preparation.md) for upgrade timing

**Performance Integration:**
- [DevTools MCP](../development-tools/mcp-servers/devtools-mcp.md) — Testing with fast 200 tokens/sec response
- [Sequential Thinking MCP](../development-tools/mcp-servers/sequential-thinking-mcp.md) — Enhanced problem-solving with multiple models

## Get Started

Ready to try Synthetic.new? [Sign up with my link](https://synthetic.new/?referral=IDyp75aoQpW9YFt) to support the guide and get started with privacy-first AI model access.
